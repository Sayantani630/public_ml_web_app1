# -*- coding: utf-8 -*-
"""Project(Parkinson Disease).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PqfgGs18TXqsEwzC4gVWcu3jLZ-IHdqQ

Importing Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

parkinsons_data = pd.read_csv('/content/parkinsons.csv')
parkinsons_data

parkinsons_data.head()

parkinsons_data.shape    # number of rows and columns in the dataset

parkinsons_data.info()   # getting soe info about the data

parkinsons_data.isnull().sum()     # chceking for missing values

parkinsons_data.describe()      # statistical measure about the data

parkinsons_data['status'].value_counts()   # checking the distribution of target variable
                                      # 1 --> parkinsons positive  , 0--> parkinsons negative

parkinsons_data.groupby('status').mean    # grouping the data based on the target variable

"""Data Pre-processing (Separating the features and target)"""

X= parkinsons_data.drop(columns=['status','name'], axis=1)
Y= parkinsons_data['status']

print(X)

print(Y)

"""Spliting the data into training data and test data"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

print(Y.shape,Y_train.shape,Y_test.shape)

"""Data Standardization"""

scaler=StandardScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

print(X_train)

"""Training the model

Support Vector Machine Model
"""

model=svm.SVC(kernel='linear')

model.fit(X_train,Y_train)

"""Model Evaluation

1.Accuracy Score
"""

X_train_prediction=model.predict(X_train)                  #accuracy score on the training data
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

print('Accuracy score of the training data : ',training_data_accuracy)

X_test_prediction=model.predict(X_test)                  #accuracy score on the test data
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)

print('Accuracy score of the test data : ',test_data_accuracy)

"""2.Making a predictive system


"""

input_data=(162.56800,198.34600,77.63000,0.00502,0.00003,0.00280,0.00253,0.00841,0.01791,0.16800,0.00793,0.01057,0.01799,0.02380,0.01170,25.67800,0.427785,0.723797,-6.635729,0.209866,1.957961,0.135242)

input_data_as_numpy_array=np.asarray(input_data)          # changing the input_data to numpy array

input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)   # reshape the array as we are predicting for one instance

std_data=scaler.transform(input_data_reshaped)               #standardize the input data


prediction=model.predict(std_data)
print(prediction)


if (prediction[0]==0):
  print('The person does not have parkinsons')
else:
  print('The person have parkinsons')

input_data=(197.07600,206.89600,192.05500,0.00289,0.00001,0.00166,0.00168,0.00498,0.01098,0.09700,0.00563,0.00680,0.00802,0.01689,0.00339,26.77500,0,0.422229,0.741367,-7.348300,0.177551,1.743867,0.085569 )


input_data_features = input_data[1:]

input_data_as_numpy_array=np.asarray(input_data_features)          # changing the input_data to numpy array

input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)   # reshape the array as we are predicting for one instance

std_data=scaler.transform(input_data_reshaped)               #standardize the input data


prediction=model.predict(std_data)
print(prediction)


if (prediction[0]==0):
  print('The person does not have parkinsons')
else:
  print('The person have parkinsons')